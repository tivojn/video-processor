# Video/Audio Processor Skill

Comprehensive media processing: transcribe, translate, summarize, and dub videos/audio with professional TTS.

**Supports:**
- ðŸŽ¬ **Video files**: MP4, MKV, AVI, MOV, WebM, FLV
- ðŸŽµ **Audio files**: MP3, M4A, WAV, FLAC, OGG, AAC
- ðŸŒ **URLs**: YouTube, Twitter/X, TikTok, Instagram, and 1000+ sites via yt-dlp

## Activation

Use this skill when the user:
- Says `/video-transcribe`, `/video-translate`, `/video-dub`, or `/video-summary`
- Asks to "transcribe this video"
- Wants to "translate and dub a video"
- Needs "video summary" or "summarize this video"
- Requests "extract transcript from video"
- Asks in ANY language (e.g., "æ€»ç»“è¿™æ®µè§†é¢‘", "rÃ©sumez cette vidÃ©o", "resume este video")

**Language Detection:**
- Automatically detects the language of the user's request
- Generates output in the same language as the request
- Example: "æ€»ç»“è¿™æ®µè§†é¢‘" â†’ Summary in Chinese
- Example: "summarize this video" â†’ Summary in English
- Can be overridden with explicit language parameter

## Modes

### 1. Transcription Only
Extract transcript with timestamps from video.

**Triggers:** `/video-transcribe`, "transcribe this video"

**Output:**
- `{video_name}_transcript.srt` - Transcript with timestamps
- `{video_name}_transcript.txt` - Plain text transcript

### 2. Translation
Transcribe + translate to target language (no TTS, subtitles only).

**Triggers:** `/video-translate`, "translate this video to {lang}"

**Output:**
- `{video_name}_original.srt` - Original transcript
- `{video_name}_{target_lang}.srt` - Translated subtitles
- Side-by-side review before saving

### 3. Dubbing (Full Pipeline)
Transcribe, translate, review, TTS, create dubbed video.

**Triggers:** `/video-dub`, "dub this video to {lang}"

**Output:**
- `{video_name}_original.srt` - Original transcript
- `{video_name}_{target_lang}.srt` - Translated subtitles
- `{video_name}_{target_lang}_audio.mp3` - Synced TTS audio
- `{video_name}_dubbed.mp4` - Final dubbed video with dual subs

### 4. Summary
Transcribe video and generate comprehensive summary.

**Triggers:**
- `/video-summary`, "summarize this video" (English)
- "æ€»ç»“è¿™æ®µè§†é¢‘" (Chinese)
- "rÃ©sumez cette vidÃ©o" (French)
- "resume este video" (Spanish)
- Any natural language request

**Output:**
- `{video_name}_summary.md` - Comprehensive summary:
  - Overview (2-3 sentences)
  - Key points (bullet list)
  - Detailed summary
  - Important timestamps
  - Action items (if applicable)

**Language Detection (Automatic):**
- Detects request language and generates summary in that language
- "What's this video about?" â†’ English summary
- "æ€»ç»“è¿™æ®µè§†é¢‘" â†’ Chinese summary
- "è¿™ä¸ªè§†é¢‘è®²ä»€ä¹ˆï¼Ÿ" â†’ Chinese summary
- Can override with explicit parameter: `/video-summary video.mp4 spanish`

## Parameters

- `input` (required): Path to video/audio file OR URL
  - Local: `video.mp4`, `audio.mp3`, `podcast.m4a`
  - URL: `https://youtube.com/watch?v=xxx`, `https://twitter.com/user/status/xxx`
- `target_lang` (optional): Target language (chinese, spanish, french, etc.)
- `groq_api_key` (optional): Groq API key (will prompt if not in env)

## Features

- âœ… **Audio + Video support** (MP4, MP3, WAV, M4A, and more)
- âœ… **URL download** (YouTube, Twitter, TikTok, 1000+ sites)
- âœ… Ultra-fast transcription (Groq Whisper Large V3)
- âœ… Natural translation (context-aware, preserves technical terms)
- âœ… **Segment-by-segment TTS** (precise timing per subtitle)
- âœ… **Perfect audio sync** (automatic speed adjustment per segment)
- âœ… **Voice cloning support** (use any voicebox profile)
- âœ… Translation review (edit before TTS generation)
- âœ… **Auto subtitle embedding** (always adds original language subs)
- âœ… Dual subtitle support (original + translated)
- âœ… Multi-language TTS (Kokoro + edge-tts + voicebox)
- âœ… Intelligent summaries (with timestamps and key points)
- âœ… **Language-aware detection** (auto-detects request language)

## Requirements

- ffmpeg (video/audio processing)
- yt-dlp (URL downloads)
- Groq API key (transcription & translation)
- Optional: Kokoro TTS (Chinese, local)
- Optional: edge-tts (50+ languages, cloud)

## Example Sessions

**Transcription (Video/Audio/URL):**
```
User: "Transcribe this video"
Claude: Extracts transcript â†’ video_transcript.srt + video_transcript.txt

User: "Transcribe podcast.mp3"
Claude: Extracts audio transcript â†’ podcast_transcript.srt + podcast_transcript.txt

User: "Transcribe https://youtube.com/watch?v=xxx"
Claude: Downloads video â†’ Transcribes â†’ transcript files
```

**Summary (Language-Aware):**
```
User: "What's this video about?"
Claude: Transcribes â†’ Generates English summary in video_summary.md

User: "æ€»ç»“è¿™æ®µè§†é¢‘" (video.mp4)
Claude: Transcribes â†’ Generates Chinese summary in video_summary.md

User: "Summarize https://twitter.com/user/status/xxx"
Claude: Downloads â†’ Transcribes â†’ Generates English summary

User: "è¿™ä¸ªYouTubeè§†é¢‘è®²ä»€ä¹ˆï¼Ÿhttps://youtube.com/watch?v=xxx"
Claude: Downloads â†’ Transcribes â†’ Detects Chinese â†’ Generates Chinese summary
```

**Dubbing (Audio Support):**
```
User: "Dub this to Chinese"
Claude: Transcribe â†’ Translate â†’ Review â†’ TTS â†’ Dubbed video

User: "æŠŠè¿™ä¸ªéŸ³é¢‘é…éŸ³æˆä¸­æ–‡" (podcast.mp3)
Claude: Transcribe audio â†’ Translate to Chinese â†’ Review â†’ TTS

User: "Dub this YouTube video to Spanish: https://youtube.com/watch?v=xxx"
Claude: Downloads â†’ Transcribes â†’ Translates â†’ TTS â†’ Dubbed video
```

## Technical Details

### Segment-by-Segment TTS Processing

The dubbing system uses a 3-step pipeline that scales to 1500+ segments:

1. **Parse SRT** - Each subtitle entry becomes a separate TTS generation
2. **Generate per segment** - TTS generated for each segment independently
   - **edge-tts**: Async parallel generation in batches of 10 (fastest for large files)
   - **Kokoro**: Single-process batch generation via KPipeline
   - **voicebox**: Sequential generation with voice cloning
3. **Speed adjustment** - Each segment's speed adjusted to match exact subtitle duration
   - Uses ffmpeg `atempo` filter chain (supports 0.5x - 4.0x range)
   - Chains multiple atempo filters for extreme ratios (>2x or <0.5x)
4. **Numpy timeline assembly** - Places each adjusted segment at its exact SRT start position
   in a pre-allocated numpy array. This replaces the old ffmpeg concat/amix approach and
   scales to any number of segments without hitting ffmpeg input limits.
5. **Video mux** - Uses `-c:v copy` (no re-encode) + soft subtitle tracks for speed

**Performance (tested on 2h22m video, 1,554 segments):**
- edge-tts TTS generation: ~12 min (parallel batches of 10)
- Speed adjustment: ~48s
- Numpy timeline assembly: ~1.3s
- Video muxing: ~43s
- **Total: ~14 min for a 2h22m video**

**Benefits:**
- Scales to 1500+ segments (numpy, not ffmpeg amix)
- edge-tts parallel batches for 10x faster generation
- No video re-encoding (`-c:v copy`)
- Soft subtitle tracks (toggle in player)
- Resume support (skips already-generated segments)

### TTS Engine Selection

**Default: edge-tts** â€” Used automatically unless the user explicitly requests otherwise.
- Male default: `en-US-BrianMultilingualNeural` (Brian Multilingual)
- Female default: `en-US-EmmaMultilingualNeural` (Emma Multilingual)
- These multilingual voices handle all target languages natively
- If user doesn't specify gender, default to Brian Multilingual (Male)
- Full voice list: `edge-tts --list-voices`

**Kokoro (local, no internet)** â€” Only used when the user explicitly asks for Kokoro.
- Trigger phrases: "use Kokoro", "use local TTS", "offline TTS"
- English: `am_michael`, `am_adam`, `af_heart`
- Chinese: `zf_001` (and 100+ Chinese voices)

**Voicebox (voice cloning/design)** â€” Used when the user requests a specific voice persona, cloned voice, or voice description. Three scenarios:

**Scenario A: Cloned voice** â€” User asks for a known cloned voice (e.g., "use Trump's voice")
- Search for the existing clone voice profile in voicebox
- Use it directly for TTS
- Example: "Dub this video using Trump's voice" â†’ find `Trump_Voice` clone profile â†’ TTS with it

**Scenario B: Named designed voice** â€” User asks for a named voice persona (e.g., "use Panic Granny voice")
- Search voicebox for an existing designed profile matching the name
- If found â†’ use it for TTS
- If not found â†’ design the voice profile first via voicebox, then use it for TTS
- Example: "Dub this using Panic Granny voice" â†’ search for `Panic_Granny` profile â†’ use if exists, design if not â†’ TTS

**Scenario C: Voice description** â€” User describes voice characteristics (e.g., "a male mid-aged calm narrator")
- Use voicebox to design a new voice profile matching the description
- Then use the designed profile for TTS
- Example: "Dub this with a calm male narrator" â†’ voicebox designs voice with those traits â†’ TTS with it

```bash
# Dub with a cloned/designed voice profile
generate_tts_and_dub.sh video.mp4 original.srt translated.srt chinese "Trump_Voice"
```

**Selection logic summary:**
1. User names a cloned voice â†’ **voicebox** (find clone profile â†’ TTS)
2. User names a voice persona â†’ **voicebox** (find or design profile â†’ TTS)
3. User describes voice traits â†’ **voicebox** (design profile â†’ TTS)
4. User explicitly asks for Kokoro â†’ **Kokoro**
5. Everything else â†’ **edge-tts** (Brian Multilingual male / Emma Multilingual female)

### Same-Language Re-voicing

The dubbing pipeline supports re-voicing in the same language (no translation needed).
Use the original SRT as both the original and translated SRT:
```bash
generate_tts_and_dub.sh video.mp4 transcript.srt transcript.srt english none en-US-BrianNeural
```

## Notes

- All modes start with transcription
- Translation uses natural phrasing (not machine translation)
- Dubbing includes perfect audio-subtitle sync (segment-by-segment)
- **Always embeds original language subtitles** in output video (soft subs)
- Summaries are comprehensive but concise
- Original video quality is preserved (`-c:v copy`, no re-encode)
- Long videos (1000+ segments) handled efficiently via numpy timeline
